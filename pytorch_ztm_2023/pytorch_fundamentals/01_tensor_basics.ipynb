{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor\n",
    "1. Tensor\n",
    "2. Random tensor\n",
    "3. Zero / One tensor\n",
    "4. arange\n",
    "5. tensors-like\n",
    "6. device, dtype, shape, requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor\n",
    "- PyTorch의 가장 기본적인 building block\n",
    "- Tensor에는 ndim과 shape가 있는데 차이는 이렇다\n",
    "    - ndim  = 말 그대로 dimension이 몇개인가. 따라서 ndim은 single scalar value이다\n",
    "    - shape = 각각의 차원에 몇개의 하위 차원 요소가 들어가 있는가\n",
    "    - 예를 들면 이렇다\n",
    "        - scalar (0D)\n",
    "            - ndim = 0 (하위 차원이 없다) shape = [] (하위 차원이 없다)\n",
    "        - vector (1D)\n",
    "            - 예: [1,2,3,4]\n",
    "            - ndim = 1 (하위 차원은 scalar이고 scalar의 ndim = 0)\n",
    "            - shape = [4] (scalar가 4개 들어가 있음)\n",
    "        - matrix (2D)\n",
    "            - 예: [[1,2],[3,4],[5,6]]\n",
    "            - ndim = 2 (하위 차원은 vector이고 vector의 ndim = 1) \n",
    "            - shape = [3,2] (vector가 3개 있고 각 vector에는 scalar가 2개씩 들어가 있음)\n",
    "\n",
    "- 주로 다음과 같이 variable name이 setting된다 (scalar, vector는 lowercase, matrix, tesnor는 uppercase를 많이 쓰는 모양?)\n",
    "    - scalar : a\n",
    "    - vector : y\n",
    "    - matrix : Q\n",
    "    - tensor : X\n",
    "\n",
    "- dtype은 Tensor에 들어있는 scalar의 type을 결정한다. default는 torch.float32\n",
    "    - dtype으로 지정도 가능 (아래 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.ndim = 0    a.shape = torch.Size([])\n",
      "y1.ndim = 1    y1.shape = torch.Size([1])\n",
      "y2.ndim = 1    y2.shape = torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "a = torch.tensor(1)\n",
    "print(f'a.ndim = {a.ndim}    a.shape = {a.shape}')\n",
    "\n",
    "# Vector (1D)\n",
    "y1 = torch.tensor([1]) # Scalar와는 다르다!\n",
    "print(f'y1.ndim = {y1.ndim}    y1.shape = {y1.shape}')\n",
    "\n",
    "y2 = torch.tensor([1,2,3,4])\n",
    "print(f'y2.ndim = {y2.ndim}    y2.shape = {y2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.ndim = 2    Q1.shape = torch.Size([1, 1])\n",
      "Q2.ndim = 2    Q2.shape = torch.Size([3, 2])\n",
      "[0] : tensor([1, 2])\n",
      "[1] : tensor([3, 4])\n",
      "[2] : tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Matrix (2D)\n",
    "Q1 = torch.tensor([[1]])\n",
    "print(f'Q1.ndim = {Q1.ndim}    Q1.shape = {Q1.shape}')\n",
    "\n",
    "Q2 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(f'Q2.ndim = {Q2.ndim}    Q2.shape = {Q2.shape}')\n",
    "for i, y in enumerate(Q2):\n",
    "    print(f'[{i}] : {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.ndim = 3    X1.shape = torch.Size([1, 1, 1])\n",
      "X2.ndim = 3    X2.shape = torch.Size([2, 2, 2])\n",
      "[0] : tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[1] : tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor (ND)\n",
    "X1 = torch.tensor([[[1]]])\n",
    "print(f'X1.ndim = {X1.ndim}    X1.shape = {X1.shape}')\n",
    "\n",
    "X2 = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(f'X2.ndim = {X2.ndim}    X2.shape = {X2.shape}')\n",
    "for i,d2 in enumerate(X2):\n",
    "    print(f'[{i}] : {d2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.int64\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "torch.float32\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# dtype\n",
    "Q1 = torch.tensor([[1,2],[3,4]])\n",
    "print(Q1)\n",
    "print(Q1.dtype)\n",
    "\n",
    "Q2 = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "print(Q2)\n",
    "print(Q2.dtype)\n",
    "\n",
    "Q3 = torch.tensor([[1,2],[3,4]], dtype=torch.float16)\n",
    "print(Q3)\n",
    "print(Q3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Tensor\n",
    "- torch.rand\n",
    "    - uniform distribution on the interval `[0,1)` 을 만든다\n",
    "    - 기본적으로 shape을 지정해 주면 됨\n",
    "    - 더 자세한 것은 다음을 참고 : https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7307, 0.4293, 0.1546],\n",
      "          [0.0594, 0.5691, 0.4507],\n",
      "          [0.3859, 0.7255, 0.0970]],\n",
      "\n",
      "         [[0.2026, 0.3824, 0.0188],\n",
      "          [0.0123, 0.6303, 0.1415],\n",
      "          [0.0778, 0.8893, 0.0672]],\n",
      "\n",
      "         [[0.8131, 0.2966, 0.9802],\n",
      "          [0.1207, 0.1153, 0.4635],\n",
      "          [0.3427, 0.2692, 0.9562]]],\n",
      "\n",
      "\n",
      "        [[[0.0842, 0.8079, 0.6057],\n",
      "          [0.8725, 0.1093, 0.2645],\n",
      "          [0.5275, 0.1450, 0.4379]],\n",
      "\n",
      "         [[0.1625, 0.0748, 0.4836],\n",
      "          [0.3930, 0.5092, 0.0191],\n",
      "          [0.3907, 0.0197, 0.7863]],\n",
      "\n",
      "         [[0.6305, 0.5263, 0.3548],\n",
      "          [0.4003, 0.8355, 0.1982],\n",
      "          [0.5727, 0.2624, 0.3441]]],\n",
      "\n",
      "\n",
      "        [[[0.0928, 0.5163, 0.5379],\n",
      "          [0.5936, 0.8886, 0.9892],\n",
      "          [0.5191, 0.5042, 0.6203]],\n",
      "\n",
      "         [[0.2820, 0.6489, 0.6790],\n",
      "          [0.7387, 0.9260, 0.1924],\n",
      "          [0.9359, 0.9771, 0.8868]],\n",
      "\n",
      "         [[0.6472, 0.7613, 0.0555],\n",
      "          [0.0541, 0.9731, 0.8207],\n",
      "          [0.6058, 0.1365, 0.6433]]]])\n",
      "tensor([[0.2960, 0.9685, 0.0664, 0.8166],\n",
      "        [0.8890, 0.7822, 0.9149, 0.7012],\n",
      "        [0.2082, 0.6614, 0.3685, 0.6900],\n",
      "        [0.5730, 0.0210, 0.3633, 0.1368]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Q1 = torch.rand(3,3,3,3)\n",
    "print(Q1)\n",
    "\n",
    "Q2 = torch.rand(size=(4,4)) # size를 명시적으로 넣을 수도 있다. 안 넣으면 default로 위와 같이 행동함\n",
    "print(Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zeros and Ones\n",
    "- (토막상식) Zeroes가 아님\n",
    "    - Noun Zero의 plural form은 Zeros임\n",
    "    - \"to zero\"할 때의 zero, 즉 verb인 zero의 3인칭 단수 가 zeroes임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "Qz1 = torch.zeros(size=(4,4))\n",
    "Qz2 = torch.zeros(3,3)\n",
    "\n",
    "print(Qz1)\n",
    "print(Qz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "Qo1 = torch.ones(size=(4,4))\n",
    "Qo2 = torch.ones(3,3)\n",
    "\n",
    "print(Qo1)\n",
    "print(Qo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. arange\n",
    "- range 도 있는데 이걸 쓰면 deprecation warning이 뜬다\n",
    "    - `torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end)`\n",
    "    - 대략 range가 python의 range와는 달리 `[start,end]`로 작동하니 inconsistent해서 python과 consistent한 arange를 쓰자라는 이야기\n",
    "- start, end, step을 정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n"
     ]
    }
   ],
   "source": [
    "print(torch.arange(0,10))\n",
    "print(torch.arange(start=0, end=10))\n",
    "print(torch.arange(start=0, end=20, step=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## like\n",
    "- rand_like, zeros_like, ones_like\n",
    "- dtype도 똑같이 따라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8417, 0.4414, 0.6084],\n",
      "        [0.4815, 0.1128, 0.5580],\n",
      "        [0.9749, 0.7092, 0.4462]])\n",
      "2 torch.Size([3, 3]) torch.float32\n",
      "tensor([[0.5684, 0.2741, 0.2067],\n",
      "        [0.8094, 0.2238, 0.7968],\n",
      "        [0.9620, 0.1008, 0.3497]])\n",
      "2 torch.Size([3, 3]) torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "2 torch.Size([3, 3]) torch.float32\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "2 torch.Size([3, 3]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "Q = torch.rand(size=(3,3))\n",
    "print(Q)\n",
    "print(Q.ndim, Q.shape, Q.dtype)\n",
    "\n",
    "Qr = torch.rand_like(Q)\n",
    "print(Qr)\n",
    "print(Qr.ndim, Qr.shape, Qr.dtype)\n",
    "\n",
    "Qz = torch.zeros_like(Q)\n",
    "print(Qz)\n",
    "print(Qz.ndim, Qz.shape, Qz.dtype)\n",
    "\n",
    "Qo= torch.ones_like(Q)\n",
    "print(Qo)\n",
    "print(Qo.ndim, Qo.shape, Qo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3271, 0.2192, 0.6294],\n",
      "        [0.6172, 0.2363, 0.8735],\n",
      "        [0.3789, 0.4126, 0.4844]], dtype=torch.float16)\n",
      "2 torch.Size([3, 3]) torch.float16\n",
      "tensor([[0.6650, 0.0210, 0.5049],\n",
      "        [0.8042, 0.8096, 0.7529],\n",
      "        [0.3872, 0.2222, 0.7188]], dtype=torch.float16)\n",
      "2 torch.Size([3, 3]) torch.float16\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "2 torch.Size([3, 3]) torch.float16\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float16)\n",
      "2 torch.Size([3, 3]) torch.float16\n"
     ]
    }
   ],
   "source": [
    "Q = torch.rand(size=(3,3), dtype=torch.float16)\n",
    "print(Q)\n",
    "print(Q.ndim, Q.shape, Q.dtype)\n",
    "\n",
    "Qr = torch.rand_like(Q)\n",
    "print(Qr)\n",
    "print(Qr.ndim, Qr.shape, Qr.dtype)\n",
    "\n",
    "Qz = torch.zeros_like(Q)\n",
    "print(Qz)\n",
    "print(Qz.ndim, Qz.shape, Qz.dtype)\n",
    "\n",
    "Qo= torch.ones_like(Q)\n",
    "print(Qo)\n",
    "print(Qo.ndim, Qo.shape, Qo.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device, dtype, shape, requires_grad\n",
    "- Tensor에서 가장 많이 겪는 문제 3가지는 이렇다\n",
    "    - Tensor shape가 서로 안맞아서 연산이 안됨\n",
    "    - dtype을 잘못 지정해서 서로 안맞아 연산이 안됨 / 너무 느림 / 너무 정확도가 낮음\n",
    "    - device를 잘못 지정해서 같이 연산이 안됨 / 너무 느림\n",
    "\n",
    "- device는 기본 cpu다\n",
    "    - `torch.set_default_device`를 사용하면 CUDA로 지정할 수 있다\n",
    "\n",
    "- requires_grad\n",
    "    - 이 Tensor에 대해 gradient를 track할 것인지 여부를 정하는 부분이다\n",
    "    - keras에서는 gradient tape이나 trainable같은 bool을 조작했는데 여기서는 Tensor단위로 조작하는 구나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook을 restart하고 Run All해야 원래 의도대로 나옴\n",
    "\n",
    "Q = torch.rand(size=(3,3))\n",
    "print(Q.device) # cpu\n",
    "\n",
    "Q = torch.rand(size=(3,3), device='cuda')\n",
    "print(Q.device) # cuda\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "Q = torch.rand(size=(3,3))\n",
    "print(Q.device) # cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8936, 0.6880, 0.4453],\n",
      "        [0.0473, 0.2778, 0.5786],\n",
      "        [0.0462, 0.9028, 0.7998]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[0.7575, 0.6125, 0.1070],\n",
      "        [0.4004, 0.2287, 0.3689],\n",
      "        [0.3049, 0.7245, 0.3035]], device='cuda:0')\n",
      "tensor([[0.6769, 0.4214, 0.0477],\n",
      "        [0.0190, 0.0636, 0.2135],\n",
      "        [0.0141, 0.6541, 0.2427]], device='cuda:0')\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "Q1 = torch.rand(size=(3,3), dtype=torch.float16)\n",
    "print(Q1)\n",
    "Q2 = torch.rand(size=(3,3), dtype=torch.float32)\n",
    "print(Q2)\n",
    "\n",
    "Q3 = Q1 * Q2\n",
    "\n",
    "print(Q3)\n",
    "print(Q3.dtype) # C처럼 자동으로 더 큰 타입으로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
