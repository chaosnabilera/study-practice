{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor\n",
    "1. Basics\n",
    "2. Random tensor\n",
    "3. Zero / One tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basics\n",
    "- PyTorch의 가장 기본적인 building block인 Tensor에 대해 간략히 정리한다\n",
    "- Tensor에는 ndim과 shape가 있는데 차이는 이렇다\n",
    "    - ndim  = 말 그대로 dimension이 몇개인가. 따라서 ndim은 single scalar value이다\n",
    "    - shape = 각각의 차원에 몇개의 하위 차원 요소가 들어가 있는가\n",
    "    - 예를 들면 이렇다\n",
    "        - scalar (0D)\n",
    "            - ndim = 0 (하위 차원이 없다) shape = [] (하위 차원이 없다)\n",
    "        - vector (1D)\n",
    "            - 예: [1,2,3,4]\n",
    "            - ndim = 1 (하위 차원은 scalar이고 scalar의 ndim = 0)\n",
    "            - shape = [4] (scalar가 4개 들어가 있음)\n",
    "        - matrix (2D)\n",
    "            - 예: [[1,2],[3,4],[5,6]]\n",
    "            - ndim = 2 (하위 차원은 vector이고 vector의 ndim = 1) \n",
    "            - shape = [3,2] (vector가 3개 있고 각 vector에는 scalar가 2개씩 들어가 있음)\n",
    "\n",
    "- 주로 다음과 같이 variable name이 setting된다 (scalar, vector는 lowercase, matrix, tesnor는 uppercase를 많이 쓰는 모양?)\n",
    "    - scalar : a\n",
    "    - vector : y\n",
    "    - matrix : Q\n",
    "    - tensor : X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.ndim = 0    a.shape = torch.Size([])\n",
      "y1.ndim = 1    y1.shape = torch.Size([1])\n",
      "y2.ndim = 1    y2.shape = torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "a = torch.tensor(1)\n",
    "print(f'a.ndim = {a.ndim}    a.shape = {a.shape}')\n",
    "\n",
    "# Vector (1D)\n",
    "y1 = torch.tensor([1]) # Scalar와는 다르다!\n",
    "print(f'y1.ndim = {y1.ndim}    y1.shape = {y1.shape}')\n",
    "\n",
    "y2 = torch.tensor([1,2,3,4])\n",
    "print(f'y2.ndim = {y2.ndim}    y2.shape = {y2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.ndim = 2    Q1.shape = torch.Size([1, 1])\n",
      "Q2.ndim = 2    Q2.shape = torch.Size([3, 2])\n",
      "[0] : tensor([1, 2])\n",
      "[1] : tensor([3, 4])\n",
      "[2] : tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Matrix (2D)\n",
    "Q1 = torch.tensor([[1]])\n",
    "print(f'Q1.ndim = {Q1.ndim}    Q1.shape = {Q1.shape}')\n",
    "\n",
    "Q2 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(f'Q2.ndim = {Q2.ndim}    Q2.shape = {Q2.shape}')\n",
    "for i, y in enumerate(Q2):\n",
    "    print(f'[{i}] : {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.ndim = 3    X1.shape = torch.Size([1, 1, 1])\n",
      "X2.ndim = 3    X2.shape = torch.Size([2, 2, 2])\n",
      "[0] : tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[1] : tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor (ND)\n",
    "X1 = torch.tensor([[[1]]])\n",
    "print(f'X1.ndim = {X1.ndim}    X1.shape = {X1.shape}')\n",
    "\n",
    "X2 = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(f'X2.ndim = {X2.ndim}    X2.shape = {X2.shape}')\n",
    "for i,d2 in enumerate(X2):\n",
    "    print(f'[{i}] : {d2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Tensor\n",
    "- torch.rand\n",
    "    - uniform distribution on the interval `[0,1)` 을 만든다\n",
    "    - 기본적으로 shape을 지정해 주면 됨\n",
    "    - 더 자세한 것은 다음을 참고 : https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6050, 0.2354, 0.7313],\n",
      "          [0.9576, 0.6847, 0.6515],\n",
      "          [0.5989, 0.6772, 0.2806]],\n",
      "\n",
      "         [[0.7233, 0.9037, 0.9344],\n",
      "          [0.6656, 0.9564, 0.8322],\n",
      "          [0.8974, 0.5757, 0.8264]],\n",
      "\n",
      "         [[0.8106, 0.6683, 0.3022],\n",
      "          [0.8417, 0.0432, 0.6265],\n",
      "          [0.8120, 0.5846, 0.2712]]],\n",
      "\n",
      "\n",
      "        [[[0.0847, 0.1186, 0.8437],\n",
      "          [0.0058, 0.4386, 0.6462],\n",
      "          [0.0171, 0.3045, 0.7409]],\n",
      "\n",
      "         [[0.4837, 0.0560, 0.3099],\n",
      "          [0.1864, 0.9377, 0.1452],\n",
      "          [0.2934, 0.0242, 0.1676]],\n",
      "\n",
      "         [[0.6206, 0.3123, 0.9585],\n",
      "          [0.2679, 0.1243, 0.0431],\n",
      "          [0.5561, 0.9411, 0.4161]]],\n",
      "\n",
      "\n",
      "        [[[0.2589, 0.5063, 0.0713],\n",
      "          [0.9851, 0.7414, 0.9847],\n",
      "          [0.9421, 0.5381, 0.8518]],\n",
      "\n",
      "         [[0.1171, 0.7842, 0.1319],\n",
      "          [0.7122, 0.5211, 0.6649],\n",
      "          [0.7393, 0.9506, 0.0321]],\n",
      "\n",
      "         [[0.6795, 0.0295, 0.9093],\n",
      "          [0.5692, 0.3464, 0.5335],\n",
      "          [0.1645, 0.6403, 0.3314]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Q = torch.rand(3,3,3,3)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
